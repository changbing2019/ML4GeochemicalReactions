{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d4ffe08f",
   "metadata": {},
   "source": [
    "This script is used for modeling pH of the particluar geochemical system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9bd4b688",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error,mean_squared_error,r2_score\n",
    "\n",
    "## The following are the ML models which can be used for trasinning\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "from sklearn.gaussian_process.kernels import Matern\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler,StandardScaler\n",
    "\n",
    "import timeit\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "166ccab7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "\n",
    "import numpy as np\n",
    "%matplotlib inline\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bbca8f5d",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "sns.set(style=\"darkgrid\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c59e722a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sns.set_context('talk')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12d4093",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52f6267a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "InsFile='10_PMU_02_LHS_5000_54854_02_t_P.dat'\n",
    "data5K = pd.read_csv(InsFile,sep ='\\t')\n",
    "data5K.columns =[col.strip() for col in data5K.columns]\n",
    "data5K.columns =[col.strip() for col in data5K.columns]\n",
    "data5K =data5K.iloc[:-1,:-1]\n",
    "\n",
    "conds = [((data5K['metaschoepite']>0) & (data5K['totAcid']>1.0e-9)),\n",
    "              ((data5K['metaschoepite']==0) & (data5K['totAcid']>1.0e-9)),\n",
    "              ((data5K['metaschoepite']>0) & (data5K['totAcid']<=1.0e-9)),\n",
    "              ((data5K['metaschoepite']==0) & (data5K['totAcid']<=1.0e-9)),\n",
    "]\n",
    "groups = ['group1','group2','group3','group4']\n",
    "\n",
    "data5K['group'] =np.select(conds, groups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd5801dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "11c56a6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputColNames = ['totU', 'totAcid', 'totBase'] \n",
    "## The target variables you want to simulate\n",
    "targetColumnNames=['pH', 'U_aq', 'U_s', 'U_sc', 'U_ex', 'Kd_sc', 'Kd_ex', 'metaschoepite']\n",
    "## Save training infomation to a file\n",
    "\n",
    "modeSumarryFileName = 'ModelTrainSummary.csv'\n",
    "\n",
    "scaler =  StandardScaler().fit(data5K[inputColNames].values)\n",
    "\n",
    "#Split the dataset intotrain dataset and test dataset\n",
    "trainData,testData = train_test_split(data5K,test_size=0.2, random_state=42,shuffle =True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e90cd906",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4f1ae380",
   "metadata": {},
   "outputs": [],
   "source": [
    "def GPyModel(xtrain,ytrain,OutFP):\n",
    "    \n",
    "    GPy_Model = GaussianProcessRegressor(kernel=Matern(length_scale=[1,1,1], nu=2.5), alpha= 1.0e-7,n_restarts_optimizer=10, normalize_y=True)\n",
    "    #GPy_random = RandomizedSearchCV(estimator = GPy_Model, param_distributions = random_GPyModel, scoring = 'r2',n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "    GPy_Model.fit(xtrain, ytrain)        \n",
    "    pickle.dump(GPy_Model, open(OutFP, 'wb'))             \n",
    "    # Cross Validation\n",
    "    scores = outputModelTrainningScore(GPy_Model,xtrain,ytrain,nCV=10)     \n",
    "    return GPy_Model,scores\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2a49f5b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def outputModelTrainningScore(model,X,y,nCV=10):\n",
    "    R2_score = cross_val_score(model, X, y,scoring='r2', cv=nCV)\n",
    "    RMSE_score = cross_val_score(model, X, y,scoring='neg_root_mean_squared_error', cv=10)\n",
    "    MAE_score = cross_val_score(model, X, y,scoring='neg_mean_absolute_error', cv=10) \n",
    "    R2_score_mean = R2_score.mean()\n",
    "    RMSE_score_mean = RMSE_score.mean()\n",
    "    MAE_score_mean = MAE_score.mean()\n",
    "    return [R2_score_mean,RMSE_score_mean, MAE_score_mean] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "611f13d5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mass_H2O</th>\n",
       "      <th>totU</th>\n",
       "      <th>totAcid</th>\n",
       "      <th>totBase</th>\n",
       "      <th>pH</th>\n",
       "      <th>U_aq</th>\n",
       "      <th>U_s</th>\n",
       "      <th>U_sc</th>\n",
       "      <th>U_ex</th>\n",
       "      <th>Kd_s</th>\n",
       "      <th>Kd_sc</th>\n",
       "      <th>Kd_ex</th>\n",
       "      <th>metaschoepite</th>\n",
       "      <th>group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1738</th>\n",
       "      <td>1.000050</td>\n",
       "      <td>0.000243</td>\n",
       "      <td>0.001666</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>3.0651</td>\n",
       "      <td>0.000226</td>\n",
       "      <td>0.000017</td>\n",
       "      <td>2.015400e-06</td>\n",
       "      <td>0.000015</td>\n",
       "      <td>74.502</td>\n",
       "      <td>8.90330</td>\n",
       "      <td>65.599</td>\n",
       "      <td>0.0</td>\n",
       "      <td>group2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4943</th>\n",
       "      <td>0.999969</td>\n",
       "      <td>0.000473</td>\n",
       "      <td>0.011430</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>2.0935</td>\n",
       "      <td>0.000445</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>1.784800e-07</td>\n",
       "      <td>0.000027</td>\n",
       "      <td>61.384</td>\n",
       "      <td>0.40088</td>\n",
       "      <td>60.983</td>\n",
       "      <td>0.0</td>\n",
       "      <td>group2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2916</th>\n",
       "      <td>1.000020</td>\n",
       "      <td>0.000514</td>\n",
       "      <td>0.006209</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>2.4017</td>\n",
       "      <td>0.000484</td>\n",
       "      <td>0.000030</td>\n",
       "      <td>6.335600e-07</td>\n",
       "      <td>0.000029</td>\n",
       "      <td>62.099</td>\n",
       "      <td>1.30870</td>\n",
       "      <td>60.790</td>\n",
       "      <td>0.0</td>\n",
       "      <td>group2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>0.999938</td>\n",
       "      <td>0.000041</td>\n",
       "      <td>0.014002</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.9702</td>\n",
       "      <td>0.000039</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>9.478000e-09</td>\n",
       "      <td>0.000003</td>\n",
       "      <td>68.603</td>\n",
       "      <td>0.24477</td>\n",
       "      <td>68.358</td>\n",
       "      <td>0.0</td>\n",
       "      <td>group2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3214</th>\n",
       "      <td>0.999911</td>\n",
       "      <td>0.000038</td>\n",
       "      <td>0.016997</td>\n",
       "      <td>1.000000e-09</td>\n",
       "      <td>1.8858</td>\n",
       "      <td>0.000036</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>5.882800e-09</td>\n",
       "      <td>0.000002</td>\n",
       "      <td>68.268</td>\n",
       "      <td>0.16486</td>\n",
       "      <td>68.103</td>\n",
       "      <td>0.0</td>\n",
       "      <td>group2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mass_H2O      totU   totAcid       totBase      pH      U_aq       U_s  \\\n",
       "1738  1.000050  0.000243  0.001666  1.000000e-09  3.0651  0.000226  0.000017   \n",
       "4943  0.999969  0.000473  0.011430  1.000000e-09  2.0935  0.000445  0.000027   \n",
       "2916  1.000020  0.000514  0.006209  1.000000e-09  2.4017  0.000484  0.000030   \n",
       "1595  0.999938  0.000041  0.014002  1.000000e-09  1.9702  0.000039  0.000003   \n",
       "3214  0.999911  0.000038  0.016997  1.000000e-09  1.8858  0.000036  0.000002   \n",
       "\n",
       "              U_sc      U_ex    Kd_s    Kd_sc   Kd_ex  metaschoepite   group  \n",
       "1738  2.015400e-06  0.000015  74.502  8.90330  65.599            0.0  group2  \n",
       "4943  1.784800e-07  0.000027  61.384  0.40088  60.983            0.0  group2  \n",
       "2916  6.335600e-07  0.000029  62.099  1.30870  60.790            0.0  group2  \n",
       "1595  9.478000e-09  0.000003  68.603  0.24477  68.358            0.0  group2  \n",
       "3214  5.882800e-09  0.000002  68.268  0.16486  68.103            0.0  group2  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainData.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad2020f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9b75d59",
   "metadata": {},
   "outputs": [],
   "source": [
    "groupLst=[]\n",
    "varLst = []\n",
    "modelTypeLst = []\n",
    "trainScore = []\n",
    "dfTestResults = pd.DataFrame()\n",
    "groups = trainData['group'].unique()\n",
    "for i, group in enumerate(groups):\n",
    "    outFolder = os.path.join(dataFolder,'SavedModel',group)\n",
    "    if not os.path.exists(outFolder):\n",
    "         os.makedirs(outFolder)\n",
    "    \n",
    "    trainGroupData = trainData[trainData['group']==group]\n",
    "    testGroupData = testData[testData['group']==group]\n",
    "    for col in targetColumnNames: \n",
    "        # CHeck the col is in the dataFrame\n",
    "        if col not in trainGroupData.columns:\n",
    "            sys.exit('The target column is not defined in the dataset, please check!')                \n",
    "        \n",
    "        print('Training With ===>', group,'Target==>',col)\n",
    "        \n",
    "        trainDataX=trainGroupData[inputColNames];\n",
    "        trainDataY = trainGroupData[col]\n",
    "\n",
    "        ## Check the max and min value of Y\n",
    "        ## IF change of Y is less than 1%,\n",
    "        ## then the target will be considered as constant, and \n",
    "        ## this value will be applied to the group\n",
    "        \n",
    "        X = trainDataX.values\n",
    "        Y = trainDataY.values\n",
    "        if Y.max()+Y.min() != 0:\n",
    "            percnt = (Y.max()-Y.min())/(Y.max()+Y.min())*200.0\n",
    "        else:\n",
    "            percnt =0.0\n",
    "        if percnt <1.0:\n",
    "            fileName = os.path.join(outFolder,'const_'+col+'.csv')\n",
    "            constVal = (Y.max()+Y.min())*0.5\n",
    "            tempdf = pd.DataFrame({'var':[col],'const':[constVal]})\n",
    "            tempdf.to_csv(fileName,index=False)\n",
    "            modelTypeLst.append('CONST')\n",
    "            trainScore.append([0,0,0])\n",
    "            groupLst.append(group)\n",
    "            varLst.append(col)\n",
    "            groupPredDF = pd.DataFrame({'testDataY':testGroupData[col].values,\n",
    "                                        'predDataY':[constVal]*len(testGroupData),\n",
    "                                        'predCI_low':[constVal]*len(testGroupData),\n",
    "                                        'predCI_upp':[constVal]*len(testGroupData),\n",
    "                                        'group':[group]*len(testGroupData),\n",
    "                                        'var':[col]*len(testGroupData),\n",
    "                                        'modelType':['CONST']*len(testGroupData)}) \n",
    "            if len(dfTestResults)==0:\n",
    "                dfTestResults = groupPredDF\n",
    "            else:\n",
    "                dfTestResults = pd.concat([dfTestResults,groupPredDF],axis=0)\n",
    "                \n",
    "            continue\n",
    "            \n",
    "        # Check the correlation of each of dataX to DataY \n",
    "        corrLst = []\n",
    "        for colX in trainDataX.columns:\n",
    "            corr = trainDataX[colX].corr(trainDataY)\n",
    "            corrLst.append(abs(corr))\n",
    "        \n",
    "        if max(corrLst)>=0.99:   # we use a linear model to simulate\n",
    "            #give the X and Y for fiting a linear model                   \n",
    "            regLinear = LinearRegression().fit(X, Y) \n",
    "            # conduct cross validation\n",
    "            scores = outputModelTrainningScore(regLinear,X,Y,nCV=10)     \n",
    "            trainScore.append(scores)\n",
    "            groupLst.append(group)\n",
    "            varLst.append(col)\n",
    "            modelTypeLst.append('linear')  \n",
    "            fileName = os.path.join(outFolder,'linear_'+col+'.sav')\n",
    "            pickle.dump(regLinear, open(fileName, 'wb'))    \n",
    "            testX = testGroupData[inputColNames].values\n",
    "            testY = testGroupData[col].values\n",
    "            predY = regLinear.predict(testX)\n",
    "            groupPredDF = pd.DataFrame({'testDataY':testY,\n",
    "                                        'predDataY':predY,\n",
    "                                        'predCI_low':predY,\n",
    "                                        'predCI_upp':predY,\n",
    "                                        'group':[group]*len(testGroupData),\n",
    "                                        'var':[col]*len(testGroupData),\n",
    "                                        'modelType':['Linear']*len(testGroupData)}) \n",
    "            \n",
    "            if len(dfTestResults)==0:\n",
    "                dfTestResults = groupPredDF\n",
    "            else:\n",
    "                dfTestResults = pd.concat([dfTestResults,groupPredDF],axis=0)\n",
    "            \n",
    "            continue\n",
    "            \n",
    "            \n",
    "        fileName = os.path.normpath( os.path.join( outFolder,'GPyModel_'+col+'.sav' ) )             \n",
    "        X_scaled = scaler.transform(X)  \n",
    "        GPy,scores = GPyModel(X_scaled,Y,fileName)\n",
    "        groupLst.append(group)\n",
    "        varLst.append(col)\n",
    "        modelTypeLst.append('GPyModel')  \n",
    "        trainScore.append(scores)\n",
    "        \n",
    "        testX = testGroupData[inputColNames].values\n",
    "        testX_scaled = scaler.transform(testX) \n",
    "        testY = testGroupData[col].values\n",
    "        predY,predYStd = GPy.predict(testX_scaled, return_std=True)\n",
    "        CI_low = predY - predYStd\n",
    "        CI_upp = predY + predYStd\n",
    "        groupPredDF = pd.DataFrame({'testDataY':testY,\n",
    "                                    'predDataY':predY,\n",
    "                                    'predCI_low':CI_low,\n",
    "                                    'predCI_upp':CI_upp,\n",
    "                                    'group':[group]*len(testGroupData),\n",
    "                                    'var':[col]*len(testGroupData),\n",
    "                                    'modelType':['GPY']*len(testGroupData)}) \n",
    "        if len(dfTestResults)==0:\n",
    "            dfTestResults = groupPredDF\n",
    "        else:\n",
    "            dfTestResults = pd.concat([dfTestResults,groupPredDF],axis=0)\n",
    "        \n",
    "        \n",
    "ModelTrainSummary = pd.DataFrame({'group':groupLst,'var':varLst,'modelType':modelTypeLst})\n",
    "ModelTrainMeasures = pd.DataFrame(trainScore,columns=['R2_mean','RMSE_mean','MAE_mean'])\n",
    "ModelTrainSummary = pd.concat([ModelTrainSummary,ModelTrainMeasures],axis=1)\n",
    "ModelTrainSummary.to_csv(modeSumarryFileName, index =False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9b6eb3f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b6ab566",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfTestResults.to_csv('SimulatedReusltsWithTestDataset.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a465c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "def drawPlotsV2(trgVar,df,simulation,scale):\n",
    "    \n",
    "    fig, ax =plt.subplots(figsize=(8,8))\n",
    "    df = df.sort_values(by=['testDataY'])\n",
    "    axMax = max(df['testDataY'].max(),df['predDataY'].max())\n",
    "    axMax =axMax +axMax*0.05\n",
    "    axMin = min(df['testDataY'].min(),df['predDataY'].min())\n",
    "    axMin = axMin - axMin*0.05\n",
    "    x2= np.linspace(axMin,axMax,30);\n",
    "    y2 = x2\n",
    "    df1 = df[df['group']=='group1']\n",
    "    df1 =df1.reset_index(drop=True)\n",
    "    ax.fill_between(df1['testDataY'], df1['predCI_low'],  df1['predCI_upp'], alpha=0.6)\n",
    "    ax.plot(df1['testDataY'],df1['predDataY'],'bo',markersize =12,label ='Group 1')\n",
    "    df2 = df[df['group']=='group2']\n",
    "    df2 =df2.reset_index(drop=True)\n",
    "    ax.fill_between(df2['testDataY'], df2['predCI_low'],  df2['predCI_upp'], alpha=0.6)\n",
    "    ax.plot(df2['testDataY'],df2['predDataY'],'go',markersize =6,label ='Group 2')\n",
    "    df3 = df[df['group']=='group3']\n",
    "    df3 =df3.reset_index(drop=True)\n",
    "    ax.fill_between(df3['testDataY'], df3['predCI_low'],  df3['predCI_upp'], alpha=0.6)\n",
    "    ax.plot(df3['testDataY'],df3['predDataY'],'yo',markersize =12,label ='Group 3')\n",
    "\n",
    "    ax.plot(x2,y2,'r-',lw=3,label ='1:1 ratio')\n",
    "    ax.legend (loc='best',ncol=5)           \n",
    "    ax.set_xlim(axMin,axMax)\n",
    "    ax.set_ylim(axMin,axMax)\n",
    "    ax.legend (loc='best',ncol=2)\n",
    "    if scale=='log':\n",
    "        ax.set_xscale('log')\n",
    "        ax.set_yscale('log')\n",
    "    ax.set_title(simulation+ ' ====> '+trgVar)\n",
    "    ax.set_xlabel('testDataY')\n",
    "    ax.set_ylabel('PredDataY')    \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c0f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlot = dfTestResults[dfTestResults['var']=='pH']\n",
    "drawPlotsV2('pH',dfPlot,'GPy',scale='no')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6069c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dfPlot = dfTestResults[dfTestResults['var']=='nSi(aq)']\n",
    "drawPlotsV2('nSi(aq)',dfPlot,'GPy',scale='log')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2bc8c2c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
